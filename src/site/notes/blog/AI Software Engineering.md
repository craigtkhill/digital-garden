---
{"dg-publish":true,"permalink":"/blog/ai-software-engineering/","tags":["blogged","ai","refactored","shared"],"created":"2025-08-26T19:42:38.799+01:00","updated":"2025-11-30T15:21:42.046+00:00"}
---

Coding was once fun. [[blog/AI made coding not fun\|Then AI came along.]]

I notice that as LLMs take bigger and bigger steps, the quality of their output declines. Sure, they might do fantastically on benchmarks, but their benchmarks do not match any [[blog/Software Engineering Goals\|real-world use case]].

I subscribe to a healthy mix of critics and optimists in my AI reading diet, and I consider myself equal parts AI skeptic, AI advocate, but I try to hold in my mind that the current models and algorithms are less Artificial Intelligence and more *Articulate Idiots*.

It does so much so well on the surface, but when I dig a little deeper, and have done enough reading and studying to be opinionated about a topic, I find so much of what it outputs is wrong or substandard. And with longer and longer outputs to audit, this becomes frustrating.

So it's difficult to rely on their APIs for a stable workflow. I'm not saying we should stop using [[blog/Keep AI on the leash\|AI for development]]. [[blog/Limit AI Use\|But we should stop relying on it]]. I don't want AI tools that write all the code. I want tools to [[blog/Requirements for a better AI collabration\|help me write better code]].

> [!EXAMPLE] Want to join the discussion? Discuss this thought [here](https://bsky.app/profile/craigtkhill.bsky.social/post/3lynrbggkis2y)